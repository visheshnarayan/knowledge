{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7d1c6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore.exceptions import BotoCoreError, ClientError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58b2f14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # loads variables from .env\n",
    "\n",
    "aws_access_key_id = os.getenv('AWS_ACCESS_KEY_ID')\n",
    "aws_secret_access_key = os.getenv('AWS_SECRET_ACCESS_KEY')\n",
    "aws_session_token = os.getenv('AWS_SESSION_TOKEN')  # optional\n",
    "\n",
    "session = boto3.Session(\n",
    "    aws_access_key_id=aws_access_key_id,\n",
    "    aws_secret_access_key=aws_secret_access_key,\n",
    "    aws_session_token=aws_session_token\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40b671ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up AWS Bedrock client using the existing session\n",
    "import json\n",
    "bedrock = session.client('bedrock-runtime', region_name=\"us-east-1\")\n",
    "\n",
    "\n",
    "def generate_bedrock_response(prompt, profile_arn):\n",
    "    try:\n",
    "        response = bedrock.invoke_model(\n",
    "            modelId=profile_arn,  # use ARN instead of plain modelId\n",
    "            contentType='application/json',\n",
    "            accept='application/json',\n",
    "            body=json.dumps({\n",
    "                \"anthropic_version\": \"bedrock-2023-05-31\",  # required for Claude 3/4\n",
    "                \"messages\": [\n",
    "                    {\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": prompt}]}\n",
    "                ],\n",
    "                \"max_tokens\": 256\n",
    "            })\n",
    "        )\n",
    "        result = json.loads(response['body'].read())\n",
    "        return result\n",
    "    except (BotoCoreError, ClientError) as e:\n",
    "        print(f\"Error generating response: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# reply = generate_bedrock_response(\"Hello, how are you?\")\n",
    "# print(reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12331af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reply = generate_bedrock_response(\"Hi Claude!\")\n",
    "# print(reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec8f1f76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'msg_bdrk_015o2vsw6XHUDXSs8zxAHFkt',\n",
       " 'type': 'message',\n",
       " 'role': 'assistant',\n",
       " 'model': 'claude-3-5-sonnet-20240620',\n",
       " 'content': [{'type': 'text',\n",
       "   'text': \"Hello! As an AI language model, I don't have feelings, but I'm functioning well and ready to assist you. How can I help you today?\"}],\n",
       " 'stop_reason': 'end_turn',\n",
       " 'stop_sequence': None,\n",
       " 'usage': {'input_tokens': 13, 'output_tokens': 35}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_id=\"anthropic.claude-3-5-sonnet-20240620-v1:0\"\n",
    "generate_bedrock_response(\"Hello, how are you?\", profile_arn=model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d0f09d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "twelvelabs.pegasus-1-2-v1:0 - TwelveLabs\n",
      "anthropic.claude-opus-4-1-20250805-v1:0 - Anthropic\n",
      "amazon.titan-tg1-large - Amazon\n",
      "amazon.titan-image-generator-v1:0 - Amazon\n",
      "amazon.titan-image-generator-v1 - Amazon\n",
      "amazon.titan-image-generator-v2:0 - Amazon\n",
      "amazon.nova-premier-v1:0:8k - Amazon\n",
      "amazon.nova-premier-v1:0:20k - Amazon\n",
      "amazon.nova-premier-v1:0:1000k - Amazon\n",
      "amazon.nova-premier-v1:0:mm - Amazon\n",
      "amazon.nova-premier-v1:0 - Amazon\n",
      "amazon.titan-text-premier-v1:0 - Amazon\n",
      "amazon.nova-pro-v1:0:24k - Amazon\n",
      "amazon.nova-pro-v1:0:300k - Amazon\n",
      "amazon.nova-pro-v1:0 - Amazon\n",
      "amazon.nova-lite-v1:0:24k - Amazon\n",
      "amazon.nova-lite-v1:0:300k - Amazon\n",
      "amazon.nova-lite-v1:0 - Amazon\n",
      "amazon.nova-canvas-v1:0 - Amazon\n",
      "amazon.nova-reel-v1:0 - Amazon\n",
      "amazon.nova-reel-v1:1 - Amazon\n",
      "amazon.nova-micro-v1:0:24k - Amazon\n",
      "amazon.nova-micro-v1:0:128k - Amazon\n",
      "amazon.nova-micro-v1:0 - Amazon\n",
      "amazon.nova-sonic-v1:0 - Amazon\n",
      "amazon.titan-embed-g1-text-02 - Amazon\n",
      "amazon.titan-text-lite-v1:0:4k - Amazon\n",
      "amazon.titan-text-lite-v1 - Amazon\n",
      "amazon.titan-text-express-v1:0:8k - Amazon\n",
      "amazon.titan-text-express-v1 - Amazon\n",
      "amazon.titan-embed-text-v1:2:8k - Amazon\n",
      "amazon.titan-embed-text-v1 - Amazon\n",
      "amazon.titan-embed-text-v2:0:8k - Amazon\n",
      "amazon.titan-embed-text-v2:0 - Amazon\n",
      "amazon.titan-embed-image-v1:0 - Amazon\n",
      "amazon.titan-embed-image-v1 - Amazon\n",
      "stability.stable-diffusion-xl-v1:0 - Stability AI\n",
      "stability.stable-diffusion-xl-v1 - Stability AI\n",
      "ai21.jamba-instruct-v1:0 - AI21 Labs\n",
      "ai21.jamba-1-5-large-v1:0 - AI21 Labs\n",
      "ai21.jamba-1-5-mini-v1:0 - AI21 Labs\n",
      "anthropic.claude-instant-v1:2:100k - Anthropic\n",
      "anthropic.claude-instant-v1 - Anthropic\n",
      "anthropic.claude-v2:0:18k - Anthropic\n",
      "anthropic.claude-v2:0:100k - Anthropic\n",
      "anthropic.claude-v2:1:18k - Anthropic\n",
      "anthropic.claude-v2:1:200k - Anthropic\n",
      "anthropic.claude-v2:1 - Anthropic\n",
      "anthropic.claude-v2 - Anthropic\n",
      "anthropic.claude-3-sonnet-20240229-v1:0:28k - Anthropic\n",
      "anthropic.claude-3-sonnet-20240229-v1:0:200k - Anthropic\n",
      "anthropic.claude-3-sonnet-20240229-v1:0 - Anthropic\n",
      "anthropic.claude-3-haiku-20240307-v1:0:48k - Anthropic\n",
      "anthropic.claude-3-haiku-20240307-v1:0:200k - Anthropic\n",
      "anthropic.claude-3-haiku-20240307-v1:0 - Anthropic\n",
      "anthropic.claude-3-opus-20240229-v1:0:12k - Anthropic\n",
      "anthropic.claude-3-opus-20240229-v1:0:28k - Anthropic\n",
      "anthropic.claude-3-opus-20240229-v1:0:200k - Anthropic\n",
      "anthropic.claude-3-opus-20240229-v1:0 - Anthropic\n",
      "anthropic.claude-3-5-sonnet-20240620-v1:0 - Anthropic\n",
      "anthropic.claude-3-5-sonnet-20241022-v2:0 - Anthropic\n",
      "anthropic.claude-3-7-sonnet-20250219-v1:0 - Anthropic\n",
      "anthropic.claude-3-5-haiku-20241022-v1:0 - Anthropic\n",
      "anthropic.claude-opus-4-20250514-v1:0 - Anthropic\n",
      "anthropic.claude-sonnet-4-20250514-v1:0 - Anthropic\n",
      "cohere.command-r-v1:0 - Cohere\n",
      "cohere.command-r-plus-v1:0 - Cohere\n",
      "cohere.embed-english-v3:0:512 - Cohere\n",
      "cohere.embed-english-v3 - Cohere\n",
      "cohere.embed-multilingual-v3:0:512 - Cohere\n",
      "cohere.embed-multilingual-v3 - Cohere\n",
      "deepseek.r1-v1:0 - DeepSeek\n",
      "meta.llama3-8b-instruct-v1:0 - Meta\n",
      "meta.llama3-70b-instruct-v1:0 - Meta\n",
      "meta.llama3-1-8b-instruct-v1:0 - Meta\n",
      "meta.llama3-1-70b-instruct-v1:0 - Meta\n",
      "meta.llama3-2-11b-instruct-v1:0 - Meta\n",
      "meta.llama3-2-90b-instruct-v1:0 - Meta\n",
      "meta.llama3-2-1b-instruct-v1:0 - Meta\n",
      "meta.llama3-2-3b-instruct-v1:0 - Meta\n",
      "meta.llama3-3-70b-instruct-v1:0 - Meta\n",
      "meta.llama4-scout-17b-instruct-v1:0 - Meta\n",
      "meta.llama4-maverick-17b-instruct-v1:0 - Meta\n",
      "mistral.mistral-7b-instruct-v0:2 - Mistral AI\n",
      "mistral.mixtral-8x7b-instruct-v0:1 - Mistral AI\n",
      "mistral.mistral-large-2402-v1:0 - Mistral AI\n",
      "mistral.mistral-small-2402-v1:0 - Mistral AI\n",
      "mistral.pixtral-large-2502-v1:0 - Mistral AI\n",
      "twelvelabs.marengo-embed-2-7-v1:0 - TwelveLabs\n"
     ]
    }
   ],
   "source": [
    "bedrock = boto3.client(\"bedrock\", region_name=\"us-east-1\")\n",
    "response = bedrock.list_foundation_models()\n",
    "for model in response[\"modelSummaries\"]:\n",
    "    print(model[\"modelId\"], \"-\", model[\"providerName\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fcaec7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "knowledge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
