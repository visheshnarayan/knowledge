# Configuration for the Knowledge Graph Builder

# Data Ingestion
data:
  input_dir: "data/input"

output:
  base_dir: "data/builds"
  version: "knowledge-strands-reasoning" # or a specific name like "latest", "v1", etc.
  serve_only_mode: true

# Graph Construction
graph:
  enable_consolidation: false
  chunking:
    strategy: "fixed_size"
    size: 512
    overlap: 50
  embedding:
    model: "bert-base-uncased"
  similarity:
    metric: "cosine"
    threshold: 0.8
  search_similarity: 0.4 # New parameter for agent context search similarity
  triplet_extraction:
    model: "Babelscape/rebel-large"

# Parent Model
# parent_model:
#   model: "deepseek/deepseek-r1-0528-qwen3-8b:2"

# agent_model:
#   model: "deepseek/deepseek-r1-0528-qwen3-8b:2"
#   search_sample_ratio: 0.8

llm_infra:
  type: 'strands' # 'strands' or 'lm_studio'
  strands:
    # parent_agent_model_id: "anthropic.claude-3-sonnet-20240229-v1:0"
    parent_agent_model_id: "us.deepseek.r1-v1:0"
    child_agent_model_id: "anthropic.claude-3-sonnet-20240229-v1:0"
    agent:
      system_prompt: "You are a helpful assistant that can answer questions based on the context provided. Please be concise and stick to the information given in the context."
  lm_studio:
    base_url: "http://localhost:1234/v1"
    api_key: "not-needed"
    model: "local-model"


# TODO: replace with pinecone
database:
  uri: "bolt://localhost:7687"
  user: "admin"
  password: "password"

# Debugging settings
debug:
  log_llm_responses: false